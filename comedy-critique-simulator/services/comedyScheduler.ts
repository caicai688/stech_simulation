/**
 * ğŸ­ å–œå‰§é‰´èµè°ƒåº¦å™¨ (Comedy Analysis Scheduler)
 * 
 * æ ¸å¿ƒåŠŸèƒ½:
 * 1. ç”¨æˆ·ä¼˜å…ˆç­–ç•¥ (User-First): ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·åœ¨é…ç½®é¡µé€‰æ‹©çš„æ¨¡å‹
 * 2. æ™ºèƒ½é™çº§ (Smart Fallback): ç”¨æˆ·æ¨¡å‹é™é¢‘åè‡ªåŠ¨é™çº§åˆ°å¤‡ç”¨æ¨¡å‹
 * 3. å†…å­˜ç¼“å­˜ (Memory Cache): 24å°æ—¶æœ‰æ•ˆæœŸ
 * 4. è¯·æ±‚é™æµ (Throttle): æ§åˆ¶æ¯ä¸ªæ¨¡å‹çš„å¹¶å‘æ•°
 * 5. ç»Ÿä¸€è¾“å‡ºæ ¼å¼
 * 6. å¥å£®çš„é”™è¯¯å¤„ç†
 * 
 * è°ƒåº¦ç­–ç•¥:
 * - ç¬¬ä¸€ä¼˜å…ˆçº§: ç”¨æˆ·é…ç½®çš„æ¨¡å‹ï¼ˆå¦‚æœæœ‰ API Keyï¼‰
 * - å¤‡ç”¨é™çº§: ç¯å¢ƒå˜é‡ä¸­çš„å…¶ä»–æ¨¡å‹ï¼ˆæŒ‰ Gemini -> åƒé—® -> æ™ºè°± é¡ºåºï¼‰
 * - é™é¢‘è§¦å‘: é‡åˆ° 429/timeout/quota é”™è¯¯æ—¶è‡ªåŠ¨åˆ‡æ¢ä¸‹ä¸€ä¸ªæ¨¡å‹
 */

import { GoogleGenAI } from "@google/genai";
import { SYSTEM_PROMPT, PROVIDERS } from '../constants';
import { EvaluationResult, AppConfig, HistoryItem } from '../types';
import { generateAllJudgesFeedbackGuidance } from './feedbackService';

// ==================== é…ç½®å¸¸é‡ ====================

/** æ¨¡å‹é…ç½® */
interface ModelConfig {
  name: string;
  apiKey: string | null;
  endpoint?: string;
  modelName: string;
  maxConcurrent: number; // æœ€å¤§å¹¶å‘æ•°
  timeout: number; // è¶…æ—¶æ—¶é—´ (ms)
  isUserPreferred?: boolean; // æ˜¯å¦ä¸ºç”¨æˆ·ä¼˜å…ˆé€‰æ‹©çš„æ¨¡å‹
}

/** ç¼“å­˜é¡¹ */
interface CacheItem {
  data: EvaluationResult;
  timestamp: number;
  sourceModel: string;
}

/** è¯·æ±‚é˜Ÿåˆ—é¡¹ */
interface QueueItem {
  resolve: (value: any) => void;
  reject: (error: any) => void;
  execute: () => Promise<any>;
}

// ==================== å…¨å±€çŠ¶æ€ ====================

/** å†…å­˜ç¼“å­˜ Map (24å°æ—¶æœ‰æ•ˆ) */
const cache = new Map<string, CacheItem>();

/** æ¯ä¸ªæ¨¡å‹çš„å¹¶å‘è®¡æ•°å™¨ */
const concurrentCounts = {
  gemini: 0,
  qwen: 0,
  glm: 0
};

/** æ¯ä¸ªæ¨¡å‹çš„è¯·æ±‚é˜Ÿåˆ— */
const requestQueues: {
  gemini: QueueItem[];
  qwen: QueueItem[];
  glm: QueueItem[];
} = {
  gemini: [],
  qwen: [],
  glm: []
};

// ==================== å·¥å…·å‡½æ•° ====================

/**
 * ç”Ÿæˆç¼“å­˜ Key
 * åŸºäºæ®µå­å†…å®¹å’Œå›¾ç‰‡ç”Ÿæˆå”¯ä¸€æ ‡è¯†
 */
function getCacheKey(text: string, imageBase64?: string): string {
  const imageHash = imageBase64 
    ? imageBase64.substring(0, 50) 
    : 'no-image';
  return `comedy_${text.substring(0, 100)}_${imageHash}`;
}

/**
 * ä»ç¼“å­˜è·å–ç»“æœ
 * å¦‚æœç¼“å­˜è¶…è¿‡24å°æ—¶ï¼Œè‡ªåŠ¨æ¸…é™¤
 */
function getFromCache(key: string): EvaluationResult | null {
  const item = cache.get(key);
  if (!item) return null;
  
  const now = Date.now();
  const age = now - item.timestamp;
  const MAX_AGE = 24 * 60 * 60 * 1000; // 24å°æ—¶
  
  if (age > MAX_AGE) {
    cache.delete(key);
    console.log(`[Cache] ç¼“å­˜å·²è¿‡æœŸ: ${key}`);
    return null;
  }
  
  console.log(`[Cache] å‘½ä¸­ç¼“å­˜ (${item.sourceModel}): ${key}`);
  return item.data;
}

/**
 * ä¿å­˜åˆ°ç¼“å­˜
 */
function saveToCache(key: string, data: EvaluationResult, sourceModel: string): void {
  cache.set(key, {
    data,
    timestamp: Date.now(),
    sourceModel
  });
  console.log(`[Cache] å·²ç¼“å­˜ç»“æœ (${sourceModel}): ${key}`);
}

/**
 * è·å–ç¯å¢ƒå˜é‡ä¸­çš„ API Key
 */
function getApiKey(provider: 'gemini' | 'qwen' | 'glm'): string | null {
  try {
    // @ts-ignore - Vite env variables
    const env = typeof import.meta !== 'undefined' ? import.meta.env : {};
    
    if (provider === 'gemini') {
      return env.VITE_GEMINI_API_KEY || null;
    } else if (provider === 'qwen') {
      return env.VITE_QWEN_API_KEY || null;
    } else if (provider === 'glm') {
      return env.VITE_GLM_API_KEY || null;
    }
  } catch (error) {
    console.error(`[Config] è·å– ${provider} API Key å¤±è´¥:`, error);
  }
  return null;
}

/**
 * åˆå§‹åŒ–æ¨¡å‹é…ç½®
 * ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®çš„æ¨¡å‹ï¼Œç„¶ååŠ å…¥å¤‡ç”¨æ¨¡å‹
 * 
 * @param userConfig - ç”¨æˆ·é…ç½®ï¼ˆå¯é€‰ï¼‰
 */
function initModelConfigs(userConfig?: AppConfig): ModelConfig[] {
  const configs: ModelConfig[] = [];
  
  // 1. ä¼˜å…ˆåŠ å…¥ç”¨æˆ·é…ç½®çš„æ¨¡å‹
  // ç”¨æˆ·å¯ä»¥é€‰æ‹© provider ä½†ä¸å¡« API Keyï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡çš„ Keyï¼‰
  if (userConfig?.provider) {
    const provider = userConfig.provider;
    const userApiKey = userConfig.apiKey; // ç”¨æˆ·å¡«å†™çš„ Keyï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
    const envApiKey = getApiKey(provider); // ç¯å¢ƒå˜é‡ä¸­çš„ Key
    const apiKey = userApiKey || envApiKey; // ä¼˜å…ˆç”¨æˆ· Keyï¼Œå¦åˆ™ç”¨ç¯å¢ƒ Key
    const modelName = userConfig.model;
    
    if (apiKey) {
      console.log(`[Scheduler] ç”¨æˆ·ä¼˜å…ˆé€‰æ‹©: ${provider} (${modelName}) - API Key æ¥æº: ${userApiKey ? 'ç”¨æˆ·é…ç½®' : 'ç¯å¢ƒå˜é‡'}`);
      
      if (provider === 'gemini') {
        configs.push({
          name: 'gemini',
          apiKey: apiKey,
          modelName: modelName,
          maxConcurrent: 2,
          timeout: 30000,
          isUserPreferred: true
        });
      } else if (provider === 'qwen') {
        configs.push({
          name: 'qwen',
          apiKey: apiKey,
          endpoint: PROVIDERS.qwen.endpoint,
          modelName: modelName,
          maxConcurrent: 5,
          timeout: 25000,
          isUserPreferred: true
        });
      } else if (provider === 'glm') {
        configs.push({
          name: 'glm',
          apiKey: apiKey,
          endpoint: PROVIDERS.glm.endpoint,
          modelName: modelName,
          maxConcurrent: 10,
          timeout: 20000,
          isUserPreferred: true
        });
      }
    } else {
      console.warn(`[Scheduler] ç”¨æˆ·é€‰æ‹©äº† ${provider}ï¼Œä½†æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„ API Key`);
    }
  }
  
  // 2. æ·»åŠ ç¯å¢ƒå˜é‡ä¸­çš„å¤‡ç”¨æ¨¡å‹ï¼ˆæ’é™¤å·²æ·»åŠ çš„ç”¨æˆ·æ¨¡å‹ï¼‰
  const userProvider = userConfig?.provider;
  
  // Gemini å¤‡ç”¨é…ç½®
  if (userProvider !== 'gemini') {
    const geminiKey = getApiKey('gemini');
    if (geminiKey) {
      configs.push({
        name: 'gemini',
        apiKey: geminiKey,
        modelName: 'gemini-2.0-flash-exp',
        maxConcurrent: 2,
        timeout: 30000,
        isUserPreferred: false
      });
    }
  }
  
  // åƒé—®å¤‡ç”¨é…ç½®
  if (userProvider !== 'qwen') {
    const qwenKey = getApiKey('qwen');
    if (qwenKey) {
      configs.push({
        name: 'qwen',
        apiKey: qwenKey,
        endpoint: PROVIDERS.qwen.endpoint,
        modelName: 'qwen-plus',
        maxConcurrent: 5,
        timeout: 25000,
        isUserPreferred: false
      });
    }
  }
  
  // æ™ºè°±å¤‡ç”¨é…ç½®
  if (userProvider !== 'glm') {
    const glmKey = getApiKey('glm');
    if (glmKey) {
      configs.push({
        name: 'glm',
        apiKey: glmKey,
        endpoint: PROVIDERS.glm.endpoint,
        modelName: 'glm-4-flash',
        maxConcurrent: 10,
        timeout: 20000,
        isUserPreferred: false
      });
    }
  }
  
  console.log(`[Scheduler] å·²é…ç½® ${configs.length} ä¸ªæ¨¡å‹:`, 
    configs.map(c => `${c.name}${c.isUserPreferred ? ' (ç”¨æˆ·ä¼˜å…ˆ)' : ' (å¤‡ç”¨)'}`).join(', ')
  );
  
  return configs;
}

// ==================== é™æµé˜Ÿåˆ—ç®¡ç† ====================

/**
 * æ‰§è¡Œå¸¦é™æµçš„è¯·æ±‚
 * å¦‚æœå½“å‰å¹¶å‘å·²æ»¡ï¼Œå°†è¯·æ±‚æ”¾å…¥é˜Ÿåˆ—ç­‰å¾…
 */
async function executeWithThrottle<T>(
  modelName: 'gemini' | 'qwen' | 'glm',
  maxConcurrent: number,
  executor: () => Promise<T>,
  onQueued?: () => void
): Promise<T> {
  
  // æ£€æŸ¥å½“å‰å¹¶å‘æ•°
  if (concurrentCounts[modelName] >= maxConcurrent) {
    console.log(`[Throttle] ${modelName} å¹¶å‘å·²æ»¡ (${concurrentCounts[modelName]}/${maxConcurrent})ï¼ŒåŠ å…¥é˜Ÿåˆ—`);
    
    // è§¦å‘æ’é˜Ÿå›è°ƒ
    if (onQueued) {
      onQueued();
    }
    
    // åŠ å…¥é˜Ÿåˆ—ç­‰å¾…
    return new Promise<T>((resolve, reject) => {
      requestQueues[modelName].push({
        resolve,
        reject,
        execute: executor as () => Promise<any>
      });
    });
  }
  
  // æ‰§è¡Œè¯·æ±‚
  concurrentCounts[modelName]++;
  console.log(`[Throttle] ${modelName} å¹¶å‘: ${concurrentCounts[modelName]}/${maxConcurrent}`);
  
  try {
    const result = await executor();
    return result;
  } finally {
    concurrentCounts[modelName]--;
    
    // å¤„ç†é˜Ÿåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªè¯·æ±‚
    const nextItem = requestQueues[modelName].shift();
    if (nextItem) {
      console.log(`[Throttle] ${modelName} å¤„ç†é˜Ÿåˆ—ä¸­çš„è¯·æ±‚`);
      executeWithThrottle(modelName, maxConcurrent, nextItem.execute)
        .then(nextItem.resolve)
        .catch(nextItem.reject);
    }
  }
}

// ==================== æ¨¡å‹è°ƒç”¨å‡½æ•° ====================

/**
 * è°ƒç”¨ Gemini API
 */
async function callGemini(
  text: string,
  imageBase64: string | undefined,
  config: ModelConfig,
  feedbackGuidances?: { veteran: string; zoomer: string; sarah: string }
): Promise<EvaluationResult> {
  const ai = new GoogleGenAI({ apiKey: config.apiKey! });
  
  const parts: any[] = [];
  if (imageBase64) {
    const cleanBase64 = imageBase64.split(',')[1] || imageBase64;
    parts.push({
      inlineData: {
        mimeType: 'image/jpeg',
        data: cleanBase64
      }
    });
  }
  
  // æ„å»ºå®Œæ•´ Promptï¼ˆä¸ºæ¯ä¸ªå¯¼å¸ˆæ³¨å…¥ç‹¬ç«‹çš„åé¦ˆæŒ‡å¯¼ï¼‰
  let fullSystemPrompt = SYSTEM_PROMPT;
  if (feedbackGuidances) {
    fullSystemPrompt = fullSystemPrompt
      .replace('{{VETERAN_FEEDBACK_GUIDANCE}}', feedbackGuidances.veteran)
      .replace('{{ZOOMER_FEEDBACK_GUIDANCE}}', feedbackGuidances.zoomer)
      .replace('{{SARAH_FEEDBACK_GUIDANCE}}', feedbackGuidances.sarah);
  } else {
    // æ— åé¦ˆæ•°æ®æ—¶ï¼Œç§»é™¤å ä½ç¬¦
    fullSystemPrompt = fullSystemPrompt
      .replace('{{VETERAN_FEEDBACK_GUIDANCE}}', '')
      .replace('{{ZOOMER_FEEDBACK_GUIDANCE}}', '')
      .replace('{{SARAH_FEEDBACK_GUIDANCE}}', '');
  }
  
  const finalPrompt = `${fullSystemPrompt}\n\n[JOKE CONTENT START]\n${text}\n[JOKE CONTENT END]`;
  parts.push({ text: finalPrompt });
  
  // è®¾ç½®è¶…æ—¶
  const timeoutPromise = new Promise<never>((_, reject) => {
    setTimeout(() => reject(new Error('Request timeout')), config.timeout);
  });
  
  const requestPromise = ai.models.generateContent({
    model: config.modelName,
    contents: { role: 'user', parts },
    config: {
      responseMimeType: 'application/json',
      temperature: 1,
    }
  });
  
  const response = await Promise.race([requestPromise, timeoutPromise]);
  const responseText = response.text;
  
  if (!responseText) throw new Error("AI æœªè¿”å›æ•°æ®");
  
  const cleanJson = responseText.replace(/```json/g, '').replace(/```/g, '').trim();
  return JSON.parse(cleanJson);
}

/**
 * è°ƒç”¨ OpenAI å…¼å®¹ API (åƒé—®ã€æ™ºè°±)
 */
async function callOpenAICompatible(
  text: string,
  imageBase64: string | undefined,
  config: ModelConfig,
  feedbackGuidances?: { veteran: string; zoomer: string; sarah: string }
): Promise<EvaluationResult> {
  const endpoint = `${config.endpoint}/chat/completions`;
  
  // æ„å»ºå®Œæ•´ç³»ç»Ÿ Promptï¼ˆä¸ºæ¯ä¸ªå¯¼å¸ˆæ³¨å…¥ç‹¬ç«‹çš„åé¦ˆæŒ‡å¯¼ï¼‰
  let fullSystemPrompt = SYSTEM_PROMPT;
  if (feedbackGuidances) {
    fullSystemPrompt = fullSystemPrompt
      .replace('{{VETERAN_FEEDBACK_GUIDANCE}}', feedbackGuidances.veteran)
      .replace('{{ZOOMER_FEEDBACK_GUIDANCE}}', feedbackGuidances.zoomer)
      .replace('{{SARAH_FEEDBACK_GUIDANCE}}', feedbackGuidances.sarah);
  } else {
    // æ— åé¦ˆæ•°æ®æ—¶ï¼Œç§»é™¤å ä½ç¬¦
    fullSystemPrompt = fullSystemPrompt
      .replace('{{VETERAN_FEEDBACK_GUIDANCE}}', '')
      .replace('{{ZOOMER_FEEDBACK_GUIDANCE}}', '')
      .replace('{{SARAH_FEEDBACK_GUIDANCE}}', '');
  }
  
  const messages: any[] = [
    { role: 'system', content: fullSystemPrompt }
  ];
  
  const contentParts: any[] = [
    { type: 'text', text: text || "(No Text provided, purely visual joke)" }
  ];
  
  if (imageBase64) {
    contentParts.push({
      type: 'image_url',
      image_url: { url: imageBase64 }
    });
  }
  
  messages.push({ role: 'user', content: contentParts });
  
  const body = {
    model: config.modelName,
    messages,
    temperature: 0.9,
    stream: false
  };
  
  // è®¾ç½®è¶…æ—¶
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), config.timeout);
  
  try {
    const response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${config.apiKey}`
      },
      body: JSON.stringify(body),
      signal: controller.signal
    });
    
    clearTimeout(timeoutId);
    
    if (!response.ok) {
      const errData = await response.json().catch(() => ({}));
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯ 429 é”™è¯¯
      if (response.status === 429) {
        throw new Error('RATE_LIMIT_EXCEEDED');
      }
      
      throw new Error(errData?.error?.message || `API Request Failed: ${response.status}`);
    }
    
    const data = await response.json();
    const rawContent = data.choices?.[0]?.message?.content;
    
    if (!rawContent) throw new Error("AI returned empty content");
    
    const cleanJson = rawContent.replace(/```json/g, '').replace(/```/g, '').trim();
    return JSON.parse(cleanJson);
    
  } catch (error: any) {
    clearTimeout(timeoutId);
    
    if (error.name === 'AbortError') {
      throw new Error('Request timeout');
    }
    
    throw error;
  }
}

/**
 * è°ƒç”¨å•ä¸ªæ¨¡å‹ (å¸¦é™æµ)
 */
async function callModel(
  text: string,
  imageBase64: string | undefined,
  config: ModelConfig,
  onQueued?: () => void,
  feedbackGuidances?: { veteran: string; zoomer: string; sarah: string }
): Promise<EvaluationResult> {
  return executeWithThrottle(
    config.name as 'gemini' | 'qwen' | 'glm',
    config.maxConcurrent,
    async () => {
      console.log(`[Model] è°ƒç”¨ ${config.name}...`);
      
      if (config.name === 'gemini') {
        return await callGemini(text, imageBase64, config, feedbackGuidances);
      } else {
        return await callOpenAICompatible(text, imageBase64, config, feedbackGuidances);
      }
    },
    onQueued
  );
}

// ==================== ä¸»è°ƒåº¦å‡½æ•° ====================

/**
 * ğŸ­ å–œå‰§é‰´èµåˆ†æ - ä¸»å…¥å£å‡½æ•°
 * 
 * ç‰¹æ€§:
 * - ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®çš„æ¨¡å‹
 * - é™é¢‘åè‡ªåŠ¨å¤šçº§é™çº§ (ç”¨æˆ·æ¨¡å‹ -> å¤‡ç”¨æ¨¡å‹)
 * - 24å°æ—¶ç¼“å­˜
 * - æ™ºèƒ½é™æµ
 * - ç»Ÿä¸€è¾“å‡ºæ ¼å¼
 * - æ ¹æ®ç©å®¶åé¦ˆè°ƒæ•´è¯„åˆ¤æ ‡å‡†
 * 
 * @param text - æ®µå­æ–‡æœ¬
 * @param imageBase64 - å›¾ç‰‡ Base64 (å¯é€‰)
 * @param onQueued - æ’é˜Ÿå›è°ƒå‡½æ•° (å¯é€‰)
 * @param userConfig - ç”¨æˆ·é…ç½® (å¯é€‰ï¼Œä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹)
 * @param history - å†å²è®°å½• (å¯é€‰ï¼Œç”¨äºç”Ÿæˆåé¦ˆæŒ‡å¯¼)
 * @returns è¯„å®¡ç»“æœ
 */
export async function generateComedyAnalysis(
  text: string,
  imageBase64?: string,
  onQueued?: () => void,
  userConfig?: AppConfig,
  history?: HistoryItem[]
): Promise<EvaluationResult> {
  
  // 1. æ£€æŸ¥ç¼“å­˜
  const cacheKey = getCacheKey(text, imageBase64);
  const cached = getFromCache(cacheKey);
  if (cached) {
    return cached;
  }
  
  // 2. ç”Ÿæˆåé¦ˆæŒ‡å¯¼ï¼ˆæŒ‰å¯¼å¸ˆåˆ†åˆ«ç”Ÿæˆï¼‰
  const feedbackGuidances = history && history.length > 0 
    ? generateAllJudgesFeedbackGuidance(history)
    : undefined;
  
  if (feedbackGuidances) {
    console.log('[Scheduler] å·²ä¸ºæ¯ä¸ªå¯¼å¸ˆåŠ è½½ç‹¬ç«‹çš„åé¦ˆæŒ‡å¯¼');
  }
  
  // 3. åˆå§‹åŒ–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆä¼˜å…ˆç”¨æˆ·é…ç½®ï¼‰
  const availableModels = initModelConfigs(userConfig);
  
  if (availableModels.length === 0) {
    throw new Error('æ²¡æœ‰å¯ç”¨çš„ API Keyï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®æˆ–è”ç³»ç®¡ç†å‘˜ã€‚');
  }
  
  // ä¿å­˜é…ç½®ä¾›ç›‘æ§é¢æ¿ä½¿ç”¨
  saveLastUsedConfigs(availableModels);
  
  // 4. æŒ‰é¡ºåºå°è¯•æ¯ä¸ªæ¨¡å‹ï¼ˆç”¨æˆ·ä¼˜å…ˆæ¨¡å‹åœ¨å‰ï¼‰
  const errors: string[] = [];
  
  for (let i = 0; i < availableModels.length; i++) {
    const config = availableModels[i];
    const modelLabel = config.isUserPreferred ? 'ç”¨æˆ·é€‰æ‹©' : 'å¤‡ç”¨æ¨¡å‹';
    
    try {
      console.log(`[Scheduler] å°è¯• ${modelLabel} ${i + 1}/${availableModels.length}: ${config.name} (${config.modelName})`);
      
      const result = await callModel(text, imageBase64, config, onQueued, feedbackGuidances);
      
      // æˆåŠŸï¼ä¿å­˜åˆ°ç¼“å­˜å¹¶è¿”å›
      saveToCache(cacheKey, result, config.name);
      
      if (config.isUserPreferred) {
        console.log(`[Scheduler] âœ… ç”¨æˆ·ä¼˜å…ˆæ¨¡å‹ ${config.name} è°ƒç”¨æˆåŠŸ`);
      } else {
        console.log(`[Scheduler] âœ… å¤‡ç”¨æ¨¡å‹ ${config.name} è°ƒç”¨æˆåŠŸ`);
      }
      
      return result;
      
    } catch (error: any) {
      const errorMsg = error.message || String(error);
      console.error(`[Scheduler] âŒ ${config.name} å¤±è´¥:`, errorMsg);
      
      errors.push(`${config.name}: ${errorMsg}`);
      
      // å¦‚æœæ˜¯ 429 æˆ–è¶…æ—¶é”™è¯¯ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
      const shouldFallback = 
        errorMsg.includes('RATE_LIMIT_EXCEEDED') ||
        errorMsg.includes('429') ||
        errorMsg.includes('timeout') ||
        errorMsg.includes('quota');
      
      if (shouldFallback && i < availableModels.length - 1) {
        if (config.isUserPreferred) {
          console.log(`[Scheduler] ğŸ”„ ç”¨æˆ·æ¨¡å‹é™é¢‘ï¼Œé™çº§åˆ°å¤‡ç”¨æ¨¡å‹...`);
        } else {
          console.log(`[Scheduler] ğŸ”„ é™çº§åˆ°ä¸‹ä¸€ä¸ªå¤‡ç”¨æ¨¡å‹...`);
        }
        continue;
      }
      
      // å¦‚æœæ˜¯æœ€åä¸€ä¸ªæ¨¡å‹æˆ–ä¸å¯é™çº§çš„é”™è¯¯ï¼ŒæŠ›å‡º
      if (i === availableModels.length - 1) {
        throw new Error(
          `æ‰€æœ‰æ¨¡å‹è°ƒç”¨å¤±è´¥:\n${errors.join('\n')}`
        );
      }
    }
  }
  
  // ç†è®ºä¸Šä¸ä¼šåˆ°è¿™é‡Œ
  throw new Error('è°ƒåº¦å™¨å¼‚å¸¸ï¼šæ‰€æœ‰æ¨¡å‹å‡æœªå“åº”');
}

// ==================== ç»Ÿè®¡å’Œç›‘æ§ ====================

// å­˜å‚¨æœ€è¿‘ä½¿ç”¨çš„æ¨¡å‹é…ç½®ä¿¡æ¯
let lastUsedModelConfigs: Array<{name: string, isUserPreferred: boolean, modelName: string}> = [];

/**
 * ä¿å­˜æœ€è¿‘ä½¿ç”¨çš„æ¨¡å‹é…ç½®ï¼ˆä¾›ç›‘æ§é¢æ¿ä½¿ç”¨ï¼‰
 */
function saveLastUsedConfigs(configs: ModelConfig[]) {
  lastUsedModelConfigs = configs.map(c => ({
    name: c.name,
    isUserPreferred: c.isUserPreferred || false,
    modelName: c.modelName
  }));
}

/**
 * è·å–è°ƒåº¦å™¨ç»Ÿè®¡ä¿¡æ¯
 */
export function getSchedulerStats() {
  return {
    cacheSize: cache.size,
    concurrentCounts: { ...concurrentCounts },
    queueSizes: {
      gemini: requestQueues.gemini.length,
      qwen: requestQueues.qwen.length,
      glm: requestQueues.glm.length
    },
    modelConfigs: lastUsedModelConfigs // æ–°å¢ï¼šè¿”å›æ¨¡å‹é…ç½®ä¿¡æ¯
  };
}

/**
 * æ¸…é™¤ç¼“å­˜
 */
export function clearCache() {
  const size = cache.size;
  cache.clear();
  console.log(`[Cache] å·²æ¸…é™¤ ${size} æ¡ç¼“å­˜`);
}

/**
 * è·å–ç¼“å­˜è¯¦æƒ…
 */
export function getCacheDetails() {
  const items: Array<{key: string, age: number, model: string}> = [];
  const now = Date.now();
  
  cache.forEach((value, key) => {
    items.push({
      key: key.substring(0, 50) + '...',
      age: Math.floor((now - value.timestamp) / 1000 / 60), // åˆ†é’Ÿ
      model: value.sourceModel
    });
  });
  
  return items;
}
